{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from dataloader import DiveFaceDataLoader\n","import keras\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle\n","import sys\n","import tensorflow as tf\n","import keras_vggface\n","from keras.models import Model, Sequential\n","from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Lambda, Activation, ActivityRegularization\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers, models, layers, regularizers\n","from keras.preprocessing import image\n","from keras_vggface import utils\n","from keras_vggface.vggface import VGGFace\n","from tensorflow.python.keras.backend import ndim\n","\n","import tensorflow as tf\n","from tensorflow.compat.v1 import InteractiveSession\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#load whole dataset\n","demo_data = DiveFaceDataLoader().LoadData(\"4K_120\")\n","#Set UP so its usable with keras ImageDataGenerator\n","demo_data.rename(columns={'Image':'filename'},inplace=True)\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["my_model = 'resnet50'\n","resnet = VGGFace(model = my_model)\n","\n","#Select the last leayer as feature embedding  \n","last_layer = resnet.get_layer('avg_pool').output\n","feature_layer = Flatten(name='flatten')(last_layer)\n","model_vgg=Model(resnet.input, feature_layer)\n","\n","#Freeze the model\n","model_vgg.trainable = False\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#Create the 3 subsets from the dataset (one per race)\n","#white people (about 55k images keep one per identity)\n","white_entries = demo_data.drop(['HN','HA','MN','MA'],axis=1)\n","white_entries = white_entries[demo_data['HB'] != demo_data['MB']]\n","white_entries = white_entries.drop_duplicates(\"Id\")\n","#asian people\n","asian_entries = demo_data.drop(['HN','HB','MN','MB'],axis=1)\n","asian_entries = asian_entries[demo_data['HA'] != demo_data['MA']]\n","#afroamerican people\n","afr_entries = demo_data.drop(['HA','HB','MB','MA'],axis=1)\n","afr_entries = afr_entries[demo_data['HN'] != demo_data['MN']]\n",""]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["balanced_classifier = keras.Sequential([\n","    model_vgg,\n","    keras.layers.Dense(3000,activation=\"relu\"),\n","    keras.layers.Dense(2,activation=\"softmax\")]\n",")\n","balanced_classifier.compile(loss='categorical_crossentropy',metrics=['acc'])"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["#Preprocessing used for the images\n","def preprocess(img):\n","    img = np.expand_dims(img, axis=0)\n","    return img"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["wh_mf = white_entries.rename(columns={'HB':'H','MB':'M'})\n","balanced_dataset_training = wh_mf[wh_mf['H'] == 1].head(500)\n","balanced_dataset_training = balanced_dataset_training.append(wh_mf[wh_mf['M'] == 1].head(500))\n","balanced_dataset_eval = wh_mf[wh_mf['H'] == 1].tail(250)\n","balanced_dataset_eval= balanced_dataset_eval.append(wh_mf[wh_mf['M'] == 1].tail(250)) \n","as_mf = asian_entries.rename(columns={'HA':'H','MA':'M'})\n","balanced_dataset_training = balanced_dataset_training.append(as_mf[as_mf['H'] == 1].head(500))\n","balanced_dataset_training = balanced_dataset_training.append(as_mf[as_mf['M'] == 1].head(500))\n","balanced_dataset_eval = balanced_dataset_eval.append(as_mf[as_mf['H'] == 1].tail(250)) \n","balanced_dataset_eval= balanced_dataset_eval.append(as_mf[as_mf['M'] == 1].tail(250)) \n","af_mf = afr_entries.rename(columns={'HN':'H','MN':'M'})\n","balanced_dataset_training = balanced_dataset_training.append(af_mf[af_mf['H'] == 1].head(500))\n","balanced_dataset_training = balanced_dataset_training.append(af_mf[af_mf['M'] == 1].head(500))\n","balanced_dataset_eval = balanced_dataset_eval.append(af_mf[af_mf['H'] == 1].tail(250)) \n","balanced_dataset_eval= balanced_dataset_eval.append(af_mf[af_mf['M'] == 1].tail(250)) \n",""]},{"cell_type":"code","execution_count":9,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Found 3000 validated image filenames.\nFound 1500 validated image filenames.\nFound 8000 validated image filenames.\nFound 43409 validated image filenames.\nFound 40425 validated image filenames.\n"}],"source":["training_balanced = ImageDataGenerator(preprocessing_function=preprocess).flow_from_dataframe(balanced_dataset_training,directory=\".\",target_size=(224,224),y_col=['H','M'],class_mode='raw')\n","\n","evaluation_balanced = ImageDataGenerator(preprocessing_function=preprocess).flow_from_dataframe(balanced_dataset_eval,directory=\".\",target_size=(224,224),y_col=['H','M'],class_mode='raw')\n","\n","white_full = ImageDataGenerator(preprocessing_function=preprocess).flow_from_dataframe(wh_mf,directory=\".\",target_size=(224,224),y_col=['H','M'],class_mode='raw')\n","asian_full = ImageDataGenerator(preprocessing_function=preprocess).flow_from_dataframe(as_mf,directory=\".\",target_size=(224,224),y_col=['H','M'],class_mode='raw')\n","black_full = ImageDataGenerator(preprocessing_function=preprocess).flow_from_dataframe(af_mf,directory=\".\",target_size=(224,224),y_col=['H','M'],class_mode='raw')\n"]},{"cell_type":"code","execution_count":10,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Epoch 1/3\n94/94 [==============================] - 106s 1s/step - loss: 5.8235 - acc: 0.8544 - val_loss: 0.1474 - val_acc: 0.9733\nEpoch 2/3\n94/94 [==============================] - 99s 1s/step - loss: 0.3372 - acc: 0.9549 - val_loss: 1.1984 - val_acc: 0.8727\nEpoch 3/3\n94/94 [==============================] - 101s 1s/step - loss: 0.1666 - acc: 0.9789 - val_loss: 0.2296 - val_acc: 0.9747\n"},{"output_type":"execute_result","data":{"text/plain":"<tensorflow.python.keras.callbacks.History at 0x7fa167d692d0>"},"metadata":{},"execution_count":10}],"source":["balanced_classifier.fit(training_balanced,validation_data=evaluation_balanced,\n","                               epochs=3)"]},{"cell_type":"code","execution_count":11,"metadata":{"tags":[]},"outputs":[{"output_type":"stream","name":"stdout","text":"Accuracy over Black demographic group\n1264/1264 [==============================] - 856s 678ms/step - loss: 0.2805 - acc: 0.9718\nAccuracy over Asian demographic group\n1357/1357 [==============================] - 920s 678ms/step - loss: 0.1662 - acc: 0.9819\nAccuracy over White demographic group\n250/250 [==============================] - 169s 675ms/step - loss: 0.1506 - acc: 0.9827\n"},{"output_type":"execute_result","data":{"text/plain":"[0.15064741671085358, 0.9827499985694885]"},"metadata":{},"execution_count":11}],"source":["#%% Evaluate on other races\n","#Black\n","print(\"Accuracy over Black demographic group\")\n","balanced_classifier.evaluate(black_full)\n","\n","print(\"Accuracy over Asian demographic group\")\n","balanced_classifier.evaluate(asian_full)\n","#White\n","print(\"Accuracy over White demographic group\")\n","balanced_classifier.evaluate(white_full)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10-final"},"orig_nbformat":2,"kernelspec":{"name":"python3","display_name":"Python 3"}}}