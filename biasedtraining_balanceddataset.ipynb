{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["from dataloader import DiveFaceDataLoader\n","import keras\n","import os\n","import numpy as np\n","import matplotlib.pyplot as plt\n","import pickle\n","import sys\n","import tensorflow as tf\n","import keras_vggface\n","from keras.models import Model, Sequential\n","from keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout, Flatten, Lambda, Activation, ActivityRegularization\n","from keras import backend as K\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras import optimizers, models, layers, regularizers\n","from keras.preprocessing import image\n","from keras_vggface import utils\n","from keras_vggface.vggface import VGGFace\n","from tensorflow.python.keras.backend import ndim\n","\n","import tensorflow as tf\n","from tensorflow.compat.v1 import InteractiveSession\n",""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["#load whole dataset\n","demo_data = DiveFaceDataLoader().LoadData(\"4K_120\")\n","#Set UP so its usable with keras ImageDataGenerator\n","demo_data.rename(columns={'Image':'filename'},inplace=True)\n",""]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["my_model = 'resnet50'\n","resnet = VGGFace(model = my_model)\n","\n","#Select the last leayer as feature embedding  \n","last_layer = resnet.get_layer('avg_pool').output\n","feature_layer = Flatten(name='flatten')(last_layer)\n","model_vgg=Model(resnet.input, feature_layer)\n","\n","#Freeze the model\n","model_vgg.trainable = False\n",""]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[],"source":["#Create the 3 subsets from the dataset (one per race)\n","#white people (about 55k images keep one per identity)\n","white_entries = demo_data.drop(['HN','HA','MN','MA'],axis=1)\n","white_entries = white_entries[demo_data['HB'] != demo_data['MB']]\n","white_entries = white_entries.drop_duplicates(\"Id\")\n","#asian people\n","asian_entries = demo_data.drop(['HN','HB','MN','MB'],axis=1)\n","asian_entries = asian_entries[demo_data['HA'] != demo_data['MA']]\n","#afroamerican people\n","afr_entries = demo_data.drop(['HA','HB','MB','MA'],axis=1)\n","afr_entries = afr_entries[demo_data['HN'] != demo_data['MN']]\n",""]},{"cell_type":"code","execution_count":15,"metadata":{},"outputs":[],"source":["balanced_classifier = keras.Sequential([\n","    model_vgg,\n","    keras.layers.Dense(3000,activation=\"relu\"),\n","    keras.layers.Dense(2,activation=\"softmax\")]\n",")\n","balanced_classifier.compile(loss='categorical_crossentropy',metrics=['acc'])"]},{"cell_type":"code","execution_count":17,"metadata":{},"outputs":[],"source":["#Preprocessing used for the images\n","def preprocess(img):\n","    img = np.expand_dims(img, axis=0)\n","    return img"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["                                                 filename     Id  H  B\n","112099  4K_120/HB4K_120/10115947@N02_identity_25/11378...  20000  1  0\n","112106  4K_120/HB4K_120/10188119@N06_identity_5/327316...  20001  1  0\n","112111  4K_120/HB4K_120/100224830@N05_identity_25/9503...  20002  1  0\n","112116  4K_120/HB4K_120/11504096@N08_identity_116/3067...  20003  1  0\n","112120  4K_120/HB4K_120/100021856@N08_identity_67/9466...  20004  1  0\n","...                                                   ...    ... .. ..\n","92832   4K_120/MN4K_120/10617965@N07_identity_9/344366...  16057  0  1\n","92833   4K_120/MN4K_120/10617965@N07_identity_9/344447...  16057  0  1\n","92834   4K_120/MN4K_120/10617965@N07_identity_9/344366...  16057  0  1\n","92835   4K_120/MN4K_120/47180203@N08_identity_46/10055...  16058  0  1\n","92836   4K_120/MN4K_120/47180203@N08_identity_46/10055...  16058  0  1\n","\n","[1500 rows x 4 columns]"],"text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>filename</th>\n      <th>Id</th>\n      <th>H</th>\n      <th>B</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>112099</th>\n      <td>4K_120/HB4K_120/10115947@N02_identity_25/11378...</td>\n      <td>20000</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>112106</th>\n      <td>4K_120/HB4K_120/10188119@N06_identity_5/327316...</td>\n      <td>20001</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>112111</th>\n      <td>4K_120/HB4K_120/100224830@N05_identity_25/9503...</td>\n      <td>20002</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>112116</th>\n      <td>4K_120/HB4K_120/11504096@N08_identity_116/3067...</td>\n      <td>20003</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>112120</th>\n      <td>4K_120/HB4K_120/100021856@N08_identity_67/9466...</td>\n      <td>20004</td>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>92832</th>\n      <td>4K_120/MN4K_120/10617965@N07_identity_9/344366...</td>\n      <td>16057</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>92833</th>\n      <td>4K_120/MN4K_120/10617965@N07_identity_9/344447...</td>\n      <td>16057</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>92834</th>\n      <td>4K_120/MN4K_120/10617965@N07_identity_9/344366...</td>\n      <td>16057</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>92835</th>\n      <td>4K_120/MN4K_120/47180203@N08_identity_46/10055...</td>\n      <td>16058</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>92836</th>\n      <td>4K_120/MN4K_120/47180203@N08_identity_46/10055...</td>\n      <td>16058</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>1500 rows Ã— 4 columns</p>\n</div>"},"metadata":{},"execution_count":19}],"source":"balanced_dataset"},{"cell_type":"code","execution_count":29,"metadata":{},"outputs":[],"source":["wh_mf = white_entries.rename(columns={'HB':'H','MB':'M'})\n","balanced_dataset_training = wh_mf[wh_mf['H'] == 1].head(500)\n","balanced_dataset_training = balanced_dataset_training.append(wh_mf[wh_mf['M'] == 1].head(500))\n","balanced_dataset_eval = wh_mf[wh_mf['H'] == 1].tail(250)\n","balanced_dataset_eval= balanced_dataset_eval.append(wh_mf[wh_mf['M'] == 1].tail(250)) \n","as_mf = asian_entries.rename(columns={'HA':'H','MA':'M'})\n","balanced_dataset_training = balanced_dataset_training.append(as_mf[as_mf['H'] == 1].head(500))\n","balanced_dataset_training = balanced_dataset_training.append(as_mf[as_mf['M'] == 1].head(500))\n","balanced_dataset_eval = balanced_dataset_eval.append(as_mf[as_mf['H'] == 1].tail(250)) \n","balanced_dataset_eval= balanced_dataset_eval.append(as_mf[as_mf['M'] == 1].tail(250)) \n","af_mf = afr_entries.rename(columns={'HN':'H','MN':'M'})\n","balanced_dataset_training = balanced_dataset_training.append(af_mf[af_mf['H'] == 1].head(500))\n","balanced_dataset_training = balanced_dataset_training.append(af_mf[af_mf['M'] == 1].head(500))\n","balanced_dataset_eval = balanced_dataset_eval.append(af_mf[af_mf['H'] == 1].tail(250)) \n","balanced_dataset_eval= balanced_dataset_eval.append(af_mf[af_mf['M'] == 1].tail(250)) \n",""]},{"cell_type":"code","execution_count":30,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Found 3000 validated image filenames.\nFound 1500 validated image filenames.\n"]}],"source":["training_balanced = ImageDataGenerator(preprocessing_function=preprocess).flow_from_dataframe(balanced_dataset_training,directory=\".\",target_size=(224,224),y_col=['H','M'],class_mode='raw')\n","\n","evaluation_balanced = ImageDataGenerator(preprocessing_function=preprocess).flow_from_dataframe(balanced_dataset_eval,directory=\".\",target_size=(224,224),y_col=['H','M'],class_mode='raw')\n",""]},{"cell_type":"code","execution_count":31,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/3\n","94/94 [==============================] - 79s 828ms/step - loss: 7.8486 - acc: 0.8639 - val_loss: 0.2593 - val_acc: 0.9767\n","Epoch 2/3\n","94/94 [==============================] - 77s 823ms/step - loss: 0.2552 - acc: 0.9691 - val_loss: 0.2498 - val_acc: 0.9780\n","Epoch 3/3\n","94/94 [==============================] - 77s 824ms/step - loss: 0.1625 - acc: 0.9829 - val_loss: 0.3170 - val_acc: 0.9807\n"]},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc2cf699438>"]},"metadata":{},"execution_count":31}],"source":["balanced_classifier.fit(training_balanced,validation_data=evaluation_balanced,\n","                               epochs=3)"]}],"nbformat":4,"nbformat_minor":2,"metadata":{"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":3},"orig_nbformat":2}}